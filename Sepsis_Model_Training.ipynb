{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sepsis Prediction Model - Cloud Training\n",
                "\n",
                "## Instructions\n",
                "1. **Upload Data**: Click the 'Files' icon on the left sidebar and upload your `Dataset.csv` file.\n",
                "2. **Run All**: Go to 'Runtime' > 'Run all'.\n",
                "3. **Download Model**: The trained model `sepsis_xgboost.pkl` AND `sepsis_xgboost.pkl.features` will be saved. Download BOTH."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install xgboost scikit-learn pandas numpy joblib matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import xgboost as xgb\n",
                "from sklearn.model_selection import GroupShuffleSplit\n",
                "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
                "import joblib\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(\"Libraries loaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Data Loader Class (Engineers Features)\n",
                "class DataLoader:\n",
                "    def __init__(self, filepath):\n",
                "        self.filepath = filepath\n",
                "        self.raw_df = None\n",
                "        self.processed_df = None\n",
                "\n",
                "    def load_data(self):\n",
                "        print(f\"Loading data from {self.filepath}...\")\n",
                "        self.raw_df = pd.read_csv(self.filepath)\n",
                "        print(f\"Data loaded: {self.raw_df.shape}\")\n",
                "        return self.raw_df\n",
                "\n",
                "    def preprocess(self):\n",
                "        print(\"Preprocessing data...\")\n",
                "        df = self.raw_df.copy()\n",
                "        df.sort_values(by=['Patient_ID', 'Hour'], inplace=True)\n",
                "\n",
                "        # 1. Imputation\n",
                "        print(\"Imputing missing values...\")\n",
                "        patient_ids = df['Patient_ID']\n",
                "        df = df.groupby('Patient_ID').ffill()\n",
                "        df['Patient_ID'] = patient_ids\n",
                "        df = df.fillna(df.median())\n",
                "\n",
                "        # 2. Feature Engineering\n",
                "        print(\"Engineering Time-Series Features...\")\n",
                "        vitals = ['HR', 'MAP', 'SBP', 'O2Sat', 'Temp', 'Resp']\n",
                "        if 'MAP' not in df.columns and 'SBP' in df.columns and 'DBP' in df.columns:\n",
                "             df['MAP'] = (df['SBP'] + 2*df['DBP']) / 3\n",
                "        \n",
                "        existing_vitals = [v for v in vitals if v in df.columns]\n",
                "\n",
                "        for col in existing_vitals:\n",
                "            # Lag 1\n",
                "            df[f'{col}_Lag1'] = df.groupby('Patient_ID')[col].shift(1)\n",
                "            # Delta\n",
                "            df[f'{col}_Delta'] = df[col] - df[f'{col}_Lag1']\n",
                "            # Rolling Mean (Optimized)\n",
                "            rolled = df.groupby('Patient_ID')[col].rolling(window=6, min_periods=1).mean()\n",
                "            df[f'{col}_RollMean6h'] = rolled.reset_index(level=0, drop=True)\n",
                "\n",
                "        # Handle Lag NaNs (Cold Start assumption)\n",
                "        for col in existing_vitals:\n",
                "            df[f'{col}_Lag1'] = df[f'{col}_Lag1'].fillna(df[col])\n",
                "            df[f'{col}_Delta'] = df[f'{col}_Delta'].fillna(0)\n",
                "            df[f'{col}_RollMean6h'] = df[f'{col}_RollMean6h'].fillna(df[col])\n",
                "\n",
                "        self.processed_df = df\n",
                "        print(f\"Preprocessing complete. Features: {df.shape[1]}\")\n",
                "        return self.processed_df\n",
                "\n",
                "    def split_data(self, test_size=0.2, val_size=0.1):\n",
                "        print(\"Splitting data by Patient_ID...\")\n",
                "        X = self.processed_df.drop(columns=['SepsisLabel', 'Patient_ID'])\n",
                "        y = self.processed_df['SepsisLabel']\n",
                "        groups = self.processed_df['Patient_ID']\n",
                "\n",
                "        splitter_test = GroupShuffleSplit(test_size=test_size, n_splits=1, random_state=42)\n",
                "        train_val_idx, test_idx = next(splitter_test.split(X, y, groups))\n",
                "        X_train_val = X.iloc[train_val_idx]\n",
                "        y_train_val = y.iloc[train_val_idx]\n",
                "        groups_train_val = groups.iloc[train_val_idx]\n",
                "        X_test = X.iloc[test_idx]\n",
                "        y_test = y.iloc[test_idx]\n",
                "\n",
                "        relative_val_size = val_size / (1 - test_size)\n",
                "        splitter_val = GroupShuffleSplit(test_size=relative_val_size, n_splits=1, random_state=42)\n",
                "        train_idx, val_idx = next(splitter_val.split(X_train_val, y_train_val, groups_train_val))\n",
                "\n",
                "        X_train = X_train_val.iloc[train_idx]\n",
                "        y_train = y_train_val.iloc[train_idx]\n",
                "        X_val = X_train_val.iloc[val_idx]\n",
                "        y_val = y_train_val.iloc[val_idx]\n",
                "        \n",
                "        print(f\"Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}\")\n",
                "        return X_train, y_train, X_val, y_val, X_test, y_test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Training Class (Corrected: No Early Stopping)\n",
                "class SepsisModel:\n",
                "    def __init__(self):\n",
                "        self.model = None\n",
                "\n",
                "    def train(self, X_train, y_train, X_val, y_val):\n",
                "        print(\"Initializing XGBoost...\")\n",
                "        ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
                "        \n",
                "        self.model = xgb.XGBClassifier(\n",
                "            objective='binary:logistic',\n",
                "            n_estimators=100,\n",
                "            max_depth=6,\n",
                "            learning_rate=0.1,\n",
                "            scale_pos_weight=ratio,\n",
                "            use_label_encoder=False,\n",
                "            eval_metric='auc',\n",
                "            random_state=42\n",
                "        )\n",
                "        print(\"Training...\")\n",
                "        self.model.fit(\n",
                "            X_train, y_train,\n",
                "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
                "            verbose=True\n",
                "        )\n",
                "\n",
                "    def evaluate(self, X_test, y_test):\n",
                "        print(\"\\nEvaluating...\")\n",
                "        y_probs = self.model.predict_proba(X_test)[:, 1]\n",
                "        y_preds = self.model.predict(X_test)\n",
                "\n",
                "        auc = roc_auc_score(y_test, y_probs)\n",
                "        auprc = average_precision_score(y_test, y_probs)\n",
                "        print(f\"Test AUC: {auc:.4f}\")\n",
                "        print(f\"Test AUPRC: {auprc:.4f}\")\n",
                "        print(confusion_matrix(y_test, y_preds))\n",
                "\n",
                "    def save_model(self, path='sepsis_xgboost.pkl'):\n",
                "        print(f\"Saving to {path}...\")\n",
                "        joblib.dump(self.model, path)\n",
                "        \n",
                "        # SAVE FEATURES\n",
                "        try:\n",
                "            feature_names = self.model.get_booster().feature_names\n",
                "            joblib.dump(feature_names, path + \".features\")\n",
                "            print(f\"Feature signature saved to {path}.features\")\n",
                "        except Exception as e:\n",
                "            print(f\"Warning: Could not save feature names: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Execution Pipeline\n",
                "if __name__ == \"__main__\":\n",
                "    # Check if file exists\n",
                "    if not os.path.exists('Dataset.csv'):\n",
                "        print(\"ERROR: Dataset.csv not found. Please upload it using the Files tab.\")\n",
                "    else:\n",
                "        loader = DataLoader('Dataset.csv')\n",
                "        loader.load_data()\n",
                "        loader.preprocess()\n",
                "        X_train, y_train, X_val, y_val, X_test, y_test = loader.split_data()\n",
                "\n",
                "        trainer = SepsisModel()\n",
                "        trainer.train(X_train, y_train, X_val, y_val)\n",
                "        trainer.evaluate(X_test, y_test)\n",
                "        trainer.save_model('sepsis_xgboost.pkl')\n",
                "        print(\"Done! Please download sepsis_xgboost.pkl AND sepsis_xgboost.pkl.features\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}